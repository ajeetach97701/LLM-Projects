{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     Tool(\n\u001b[1;32m     23\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetPrime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         ),\n\u001b[1;32m     27\u001b[0m ]\n\u001b[0;32m---> 30\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAgentType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHAT_CONVERSATIONAL_REACT_DESCRIPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_immediate_messages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs 48 a prime number\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# agent = initialize_agent(\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#     agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#     tools=tools, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#     return_immediate_messages=False  # Corrected typo\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/langchain/agents/initialize.py:74\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomehow both `agent` and `agent_path` are None, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis should never happen.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAgentExecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_agent_and_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/langchain/agents/agent.py:782\u001b[0m, in \u001b[0;36mAgentExecutor.from_agent_and_tools\u001b[0;34m(cls, agent, tools, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_agent_and_tools\u001b[39m(\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    780\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentExecutor:\n\u001b[1;32m    781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create from agent and tools.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/pydantic/main.py:1100\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/venv/lib/python3.11/site-packages/langchain/agents/agent.py:793\u001b[0m, in \u001b[0;36mAgentExecutor.validate_tools\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate that tools are compatible with agent.\"\"\"\u001b[39;00m\n\u001b[1;32m    792\u001b[0m agent \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 793\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    794\u001b[0m allowed_tools \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_allowed_tools()\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tools'"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\")\n",
    "def is_prime(n: int) -> bool:\n",
    "    print(type(n),\":::::::::::::::::\")\n",
    "    n=int(n)\n",
    "    if n <= 1 or (n % 2 == 0 and n > 2):\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetPrime\",\n",
    "        func=is_prime,\n",
    "        description=\"A tool that returns the `n`th prime number\",\n",
    "        ),\n",
    "]\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method=\"generate\",\n",
    "    return_immediate_messages=False\n",
    ")\n",
    "\n",
    "print(agent(\"Is 48 a prime number\"))\n",
    "\n",
    "\n",
    "# agent = initialize_agent(\n",
    "#     agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "#     tools=tools, \n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "#     max_iterations=3,\n",
    "#     early_stopping_method=\"generate\",  # Corrected typo\n",
    "#     return_immediate_messages=False  # Corrected typo\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n: int) -> bool:\n",
    "    print(type(n),\":::::::::::::::::\")\n",
    "    n=int(n)\n",
    "    if n <= 1 or (n % 2 == 0 and n > 2):\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetPrime\",\n",
    "        func=is_prime,\n",
    "        description=\"A tool that returns the `n`th prime number\",\n",
    "        ),\n",
    "]\n",
    "# agent = initialize_agent(\n",
    "#     agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "#     tools=tools, \n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "#     max_iterations=3,\n",
    "#     early_stopping_method=\"generate\",  # Corrected typo\n",
    "#     return_immediate_messages=False  # Corrected typo\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm  = ChatOpenAI(temperature=0, model = \"gpt-3.5\")\n",
    "llm_math_chain=LLMMathChain.from_llm(llm)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\",k=2,return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pip install numexpr\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain.from_llm(llm=llm)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    print(type(n),\":::::::::::::::::\")\n",
    "    n=int(n)\n",
    "    if n <= 1 or (n % 2 == 0 and n > 2):\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetPrime\",\n",
    "        func=is_prime,\n",
    "        description=\"A tool that returns the `n`th prime number\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Make sure llm and memory are defined appropriately\n",
    "# llm = ...\n",
    "# memory = ...\n",
    "\n",
    "# Call initialize_agent with correct parameters\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method=\"generate\",\n",
    "    return_immediate_messages=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetPrime\",\n",
    "        func=is_prime,\n",
    "        description=\"A tool that returns the `n`th prime number\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = initialize_agent(tools=tools, \n",
    "                         llm=llm, \n",
    "                         agent='chat-conversational-react-description', \n",
    "                         verbose=True, \n",
    "                         max_iterations=3,\n",
    "                         early_stopping_method = 'generate',\n",
    "                         memory = memory,\n",
    "                         handle_parsing_errors=True\n",
    "                         )\n",
    "\n",
    "print(agent(\"Is 48 a prime number\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = initialize_agent(\n",
    "    agent = AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    llm = llm,\n",
    "    tools= tools,\n",
    "    verbose = True, \n",
    "    early_stopping_methods = \"generate\",\n",
    "    memory= memory,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve three prime umbers from a Tool\n",
    "# multiply these together\n",
    "from langchain.agents import AgentType,initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import AgentType,Tool, initialize_agent\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain import hub\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "import os\n",
    "llm=ChatGoogleGenerativeAI(temperature=0,model=\"gemini-1.0-pro\", convert_system_message_to_human=True)\n",
    "llm_math_chain=LLMMathChain.from_llm(llm)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\",k=2,return_messages=True)\n",
    "# class CalculatorInput(BaseModel):\n",
    "#     question: str = Field()\n",
    "# class PrimeInput(BaseModel):\n",
    "#     n: int = Field()\n",
    "def is_prime(n: int) -> bool:\n",
    "    print(type(n),\":::::::::::::::::\")\n",
    "    n=int(n)\n",
    "    if n <= 1 or (n % 2 == 0 and n > 2):\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "# def get_prime(n: int, primes: dict = primes) -> str:\n",
    "#     return str(primes.get(int(n)))\n",
    "# async def aget_prime(n: int, primes: dict = primes) -> str:\n",
    "#     return str(primes.get(int(n)))\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetPrime\",\n",
    "        func=is_prime,\n",
    "        description=\"A tool that returns the `n`th prime number\",\n",
    "        # args_schema=PrimeInput,\n",
    "        # coroutine=aget_prime,\n",
    "    ),\n",
    "    # Tool.from_function(\n",
    "    #     func=llm_math_chain.run,\n",
    "    #     name=\"Calculator\",\n",
    "    #     description=\"Useful for when you need to compute mathematical expressions\",\n",
    "    #     args_schema=CalculatorInput,\n",
    "    #     coroutine=llm_math_chain.arun,\n",
    "    # ),\n",
    "]\n",
    "# prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "# prompt = prompt.partial(\n",
    "#     tools = render_text_description(tools),\n",
    "#     tool_names=\", \".join([t.name for t in tools])\n",
    "# )\n",
    "# llm_with_stop = llm.bind(stop=[\"\\nObservation\"])\n",
    "# agent = (\n",
    "#     {\n",
    "#         \"input\": lambda x:x[\"input\"],\n",
    "#         \"agent_scratchpad\":lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "#         \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | llm_with_stop\n",
    "#     | ReActSingleInputOutputParser()\n",
    "# )\n",
    "agent = initialize_agent(tools=tools,\n",
    "                         llm=llm,\n",
    "                         agent='chat-conversational-react-description',\n",
    "                         verbose=True,\n",
    "                         max_iterations=3,\n",
    "                         early_stopping_method = 'generate',\n",
    "                         memory = memory,\n",
    "                         handle_parsing_errors=True\n",
    "                         )\n",
    "print(agent(\"Is 48 a prime number\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Initialize tools\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AgentExecutor: The agent executor is the runtime for an agent. This is what actually calls the agent, executes the actions it chooses, passes the action outputs back to the agent, and repeats. In pseudocode, this looks roughly like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "tools = [DuckDuckGoSearchRun(max_result = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are a helpful assistant.\"\n",
    "    ),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\",\"{input}\"),\n",
    "    (\"placeholder\",\"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm , tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mpip install langchain_core langchain_anthropic If you're working in a Jupyter notebook, you'll need to prefix pip with a % symbol like this: %pip install langchain_core langchain_anthropic. You'll also need an Anthropic API key, which you can obtain here from their console. Once you have it, set as an environment variable named ANTHROPIC ... LangChain is an open-source framework for building applications using large language models (LLMs). Learn how to install LangChain and OpenAI, and how to use its components, chains, and agents for various tasks such as chatbots, code analysis, and text summarization. Run the code from the terminal: python my-langchain-app.py. Here's a look at my completed code and response. Now let's see how to work with the Chat Model (the one that takes in a message instead of a simple string). Update your code to this: from langchain.chat_models import ChatOpenAI. Learn how to create applications that leverage the capabilities of language models with LangChain, a framework for context-aware and sophisticated reasoning. Explore the components, modules, templates, and tools of LangChain and see examples of common use cases. LangChain is an open-source Python library that enables anyone who can write code to build LLM-powered applications. The package provides a generic interface to many foundation models, enables prompt management, and acts as a central interface to other components like prompt templates, other LLMs, external data, and other tools via agents ...\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is an open-source framework for building applications using large language models (LLMs). It allows users to create context-aware and sophisticated reasoning applications. The framework provides a generic interface to many foundation models, enables prompt management, and acts as a central interface to other components like prompt templates, other LLMs, external data, and other tools via agents. Users can leverage LangChain to build applications such as chatbots, code analysis tools, and text summarization programs. If you're interested in using LangChain, you can install it using the provided instructions and explore its components and capabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is langchain',\n",
       " 'output': \"LangChain is an open-source framework for building applications using large language models (LLMs). It allows users to create context-aware and sophisticated reasoning applications. The framework provides a generic interface to many foundation models, enables prompt management, and acts as a central interface to other components like prompt templates, other LLMs, external data, and other tools via agents. Users can leverage LangChain to build applications such as chatbots, code analysis tools, and text summarization programs. If you're interested in using LangChain, you can install it using the provided instructions and explore its components and capabilities.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools = tools, verbose=True)\n",
    "agent_executor.invoke({\"input\":\"What is langchain\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is ajeet.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's my name? Don't use tools to look this up unless you need to\",\n",
       " 'chat_history': [HumanMessage(content='hi! my name is ajeet'),\n",
       "  AIMessage(content='Hello bob!. How cani assist you today?')],\n",
       " 'output': 'Your name is ajeet.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\":\"What's my name? Don't use tools to look this up unless you need to\",\n",
    "        \"chat_history\":[\n",
    "            HumanMessage(content = \"hi! my name is ajeet\"),\n",
    "            AIMessage(content=\"Hello bob!. How cani assist you today?\")\n",
    "        ]\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
